# coding:utf-8
time_out: 200                  # timeout for crawling and storing user info
min_crawl_interal: 10           # min interal of http request
max_crawl_interal: 20           # max interal of http request
excp_interal: 5*60             # time for sleeping when crawling raises exceptions

max_search_page: 50            # max search page for crawling
max_home_page: 50              # max user home page for crawling
max_comment_page: 2000         # max comment page for crawling
max_repost_page: 2000          # max repost page for crawling
max_retries: 5                 # retry times for crawling

# You should set the args below if you login from uncommon place
# It's for verification code indentified
yundama_username: wangminghui           # account for yundama
yundama_passwd: ydm012566             # password for yundama


# The value of running_mode can be normal or quick.
# In normal mode, it will be more stable, while in quick mode, the crawling speed will
# be much faster, and the weibo account almostly will be banned
# The value of crawling mode can be accurate or normal
# In normal mode, the spider won't crawl the weibo content of "展开全文" when execute home crawl tasks or search crawl
# tasks, so the speed will be much quicker.
# In accurate mode,the spider will crawl the info of "展开全文",which will be slower, but more details will be given.


# the max number of each cookie can be shared
# if you choose quick mode, your cookie will be used util it's banned
share_host_count: 5
# the expire time(hours) of each weibo cookies



#db:
#    host: 101.132.113.50
#    port: 3306
#    user: root
#    password: BlueSnail123!
#    db_name: spider_manage
#    db_type: mysql


db:
    host: 180.97.15.181
    port: 3306
    user: root
    password: Vrv123!@#
    db_name: spider_manage
    db_type: mysql



mongo:
    host: 47.105.140.207
    port: 27017
    db_name: spider_data
    table_name: news_data

redis:
    host: 180.97.15.173
    port: 6379
#    password: abcd
    cookies: 1                   # store and fetch cookies
    # store fetched urls and results,so you can decide whether retry to crawl the urls or not
    urls: 10
    broker: 7                    # broker for celery
    backend: 8                   # backed for celery
    id_name: 8                   # user id and names，for repost info analysis
    # expire_time (hours) for redis db2, if they are useless to you, you can set the value smaller
    expire_time: 48
    master: mymaster             # redis sentinel master name
    socket_timeout: 5               # sockt timeout for redis sentinel



logging:
    log_dir : "/config"
    log_name : "spider.log"



# warning by email
email:
    # your email must open smtp & pop3 service
    server: smtp.sina.com
    port: 587
    from: xxxx@sina.com   #sendingemailaccount
    password: xxxxx          #youremailpasswd
    to: xxxx@139.com      #bind 139 email,so your phone will receive the warning message
    subject: Warning Of Weibo Spider
    warning_info: Please find out the reason why the spider stops working


algorithm:
    url_SDG: E:/Workspace/swik/algorithm/pkl/url_SDG.pkl
    url_Vocabulay: E:/Workspace/swik/algorithm/pkl/url_Vocabulary.pkl
    stop_word: E:/Workspace/swik/algorithm/pkl/stop_word
    news_url: E:/Workspace/swik/news_url.blm
